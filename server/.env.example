# Phoenix observability configuration
PHOENIX_HOST=localhost
PHOENIX_PORT=6006
PHOENIX_COLLECTOR_ENDPOINT="http://localhost:6006"

# Google Gemini configuration (recommended)
GEMINI_API_KEY=your-gemini-api-key

# Ollama configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral:7b

# Default LLM provider (gemini or ollama)
DEFAULT_LLM_PROVIDER=gemini
DEFAULT_LLM_MODEL=gemini-flash-lite-latest

# Alternative: Using Ollama for local inference
# DEFAULT_LLM_PROVIDER=ollama
# DEFAULT_LLM_MODEL=mistral:7b

# Embedding configuration
EMBEDDING_MODEL=nomic-embed-text:v1.5
EMBEDDING_DIM=768
EMBEDDING_TABLE_NAME=vectors_docling_nomic_embed

# Phoenix prompt management
AGENT_ROLE_PROMPT_ID="agent_role"
AGENT_GOAL_PROMPT_ID="agent_goal"
AGENT_BACKSTORY_PROMPT_ID="agent_backstory"
DOCUMENT_PROCESSING_PROMPT_ID="document_processing"
DOCUMENT_ANSWER_PROMPT_ID="document_answer"
DOCUMENT_DETECTION_ID="document_detection"
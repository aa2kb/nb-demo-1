# Environment variables for CrewAI with Ollama
# No API keys required when using local Ollama models

# Optional: Ollama configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral:7b